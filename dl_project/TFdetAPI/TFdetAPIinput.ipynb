{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import six.moves.urllib as urllib\n",
    "import sys\n",
    "import tarfile\n",
    "import tensorflow as tf\n",
    "import zipfile\n",
    "from distutils.version import LooseVersion, StrictVersion\n",
    "from collections import defaultdict\n",
    "from io import StringIO\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division, print_function, absolute_import\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import re\n",
    "# import cv2 \n",
    "import os\n",
    "import glob\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "import io\n",
    "import tensorflow.compat.v1 as tf\n",
    "\n",
    "from PIL import Image\n",
    "from collections import namedtuple, OrderedDict\n",
    "\n",
    "import shutil\n",
    "import urllib.request\n",
    "import tarfile\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from object_detection.utils import dataset_util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['filename', 'width', 'height', 'class', 'xmin', 'ymin', 'xmax', 'ymax']\n",
    "data_reformatted = []\n",
    "data_reformatted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(len(data['objects'])):\n",
    "    for l in range(len(data['objects'][k])):\n",
    "        line = [data['image'][k]['pathname'],\n",
    "                data['image'][k]['shape']['r'],\n",
    "                data['image'][k]['shape']['c'],\n",
    "                data['objects'][k][l]['category'],\n",
    "                data['objects'][k][l]['bounding_box']['minimum']['c'],\n",
    "                data['objects'][k][l]['bounding_box']['minimum']['r'],\n",
    "                data['objects'][k][l]['bounding_box']['maximum']['c'],\n",
    "                data['objects'][k][l]['bounding_box']['maximum']['r']]\n",
    "        data_reformatted.append(line)\n",
    "pd.DataFrame(data_reformatted,columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = pd.DataFrame(data_reformatted,columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data.to_csv('data_reformatted.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully created the TFRecords: /home/aga/jupyter/DL-projekt/malaria/data_reformatted.record\n"
     ]
    }
   ],
   "source": [
    "#adjusted from: https://github.com/datitran/raccoon_dataset\n",
    "\n",
    "# converts the csv files for training and testing data to two TFRecords files.\n",
    "# places the output in the same directory as the input\n",
    "\n",
    "\n",
    "# from object_detection.utils import dataset_util\n",
    "# %cd /content/gun_detection/models/\n",
    "\n",
    "DATA_BASE_PATH = '/home/aga/jupyter/DL-projekt/malaria/'\n",
    "image_dir = DATA_BASE_PATH +'images/'\n",
    "\n",
    "def class_text_to_int(row_label):\n",
    "    if row_label == 'red blood cell':\n",
    "        return 1\n",
    "    elif row_label == 'trophozoite':\n",
    "        return 1\n",
    "    elif row_label == 'schizont':\n",
    "        return 1\n",
    "    elif row_label == 'difficult':\n",
    "        return 1\n",
    "    elif row_label == 'ring':\n",
    "        return 1\n",
    "    elif row_label == 'leukocyte':\n",
    "        return 1\n",
    "    elif row_label == 'gametocyte':\n",
    "        return 1\n",
    "    else:\n",
    "        None\n",
    "\n",
    "\n",
    "def split(df, group):\n",
    "    data = namedtuple('data', ['filename', 'object'])\n",
    "    gb = df.groupby(group)\n",
    "    return [data(filename, gb.get_group(x)) for filename, x in zip(gb.groups.keys(), gb.groups)]\n",
    "\n",
    "def create_tf_example(group, path):\n",
    "    with tf.io.gfile.GFile(os.path.join(path, '{}'.format(group.filename)), 'rb') as fid:\n",
    "        encoded_jpg = fid.read()\n",
    "        encoded_jpg_io = io.BytesIO(encoded_jpg)\n",
    "        image = Image.open(encoded_jpg_io)\n",
    "        width, height = image.size\n",
    "        \n",
    "        filename = group.filename.encode('utf8')\n",
    "        image_format = b'jpg'\n",
    "        xmins = []\n",
    "        xmaxs = []\n",
    "        ymins = []\n",
    "        ymaxs = []\n",
    "        classes_text = []\n",
    "        classes = []\n",
    "        \n",
    "        for index, row in group.object.iterrows():\n",
    "            xmins.append(row['xmin'] / width)\n",
    "            xmaxs.append(row['xmax'] / width)\n",
    "            ymins.append(row['ymin'] / height)\n",
    "            ymaxs.append(row['ymax'] / height)\n",
    "            classes_text.append(row['class'].encode('utf8'))\n",
    "            classes.append(class_text_to_int(row['class']))\n",
    "            \n",
    "            tf_example = tf.train.Example(features=tf.train.Features(feature={\n",
    "                'image/height': dataset_util.int64_feature(height),\n",
    "                'image/width': dataset_util.int64_feature(width),\n",
    "                'image/filename': dataset_util.bytes_feature(filename),\n",
    "                'image/source_id': dataset_util.bytes_feature(filename),\n",
    "                'image/encoded': dataset_util.bytes_feature(encoded_jpg),\n",
    "                'image/format': dataset_util.bytes_feature(image_format),\n",
    "                'image/object/bbox/xmin': dataset_util.float_list_feature(xmins),\n",
    "                'image/object/bbox/xmax': dataset_util.float_list_feature(xmaxs),\n",
    "                'image/object/bbox/ymin': dataset_util.float_list_feature(ymins),\n",
    "                'image/object/bbox/ymax': dataset_util.float_list_feature(ymaxs),\n",
    "                'image/object/class/text': dataset_util.bytes_list_feature(classes_text),\n",
    "                'image/object/class/label': dataset_util.int64_list_feature(classes),\n",
    "            }))\n",
    "        return tf_example\n",
    "\n",
    "for csv in ['data_reformatted']:\n",
    "  writer = tf.io.TFRecordWriter(DATA_BASE_PATH + csv + '.record')\n",
    "  path = os.path.join(image_dir)\n",
    "  examples = pd.read_csv(DATA_BASE_PATH + csv + '.csv')\n",
    "  grouped = split(examples, 'filename')\n",
    "  for group in grouped:\n",
    "      tf_example = create_tf_example(group, path)\n",
    "      writer.write(tf_example.SerializeToString())\n",
    "    \n",
    "  writer.close()\n",
    "  output_path = os.path.join(os.getcwd(), DATA_BASE_PATH + csv + '.record')\n",
    "  print('Successfully created the TFRecords: {}'.format(DATA_BASE_PATH +csv + '.record'))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
