{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"TensorDetectionAPI.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1--zEgrq8z_JhCCuG7KvR62a8rA1lsqNc","authorship_tag":"ABX9TyON7TUXsm8/Rzwv5JFWHjCE"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"vBgvH6EiPkvk","colab_type":"text"},"source":["# New Section"]},{"cell_type":"code","metadata":{"id":"F_VVB1HPQNxy","colab_type":"code","outputId":"db68067b-3f6e-40c2-ced5-cb87fde18de1","executionInfo":{"status":"ok","timestamp":1588932976533,"user_tz":-120,"elapsed":87924,"user":{"displayName":"Agnieszka Lipska","photoUrl":"","userId":"15182219769942156159"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["!pip install -U --pre tensorflow==\"1.*\"\n","\n","!apt-get install -qq protobuf-compiler python-pil python-lxml python-tk\n","\n","!pip install -qq Cython contextlib2 pillow lxml matplotlib\n","\n","!pip install -qq pycocotools"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Collecting tensorflow==1.*\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9a/d9/fd234c7bf68638423fb8e7f44af7fcfce3bcaf416b51e6d902391e47ec43/tensorflow-1.15.2-cp36-cp36m-manylinux2010_x86_64.whl (110.5MB)\n","\u001b[K     |████████████████████████████████| 110.5MB 98kB/s \n","\u001b[?25hRequirement already satisfied, skipping upgrade: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.*) (1.28.1)\n","Requirement already satisfied, skipping upgrade: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.*) (1.1.0)\n","Requirement already satisfied, skipping upgrade: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.*) (3.2.1)\n","Requirement already satisfied, skipping upgrade: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.*) (0.34.2)\n","Requirement already satisfied, skipping upgrade: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.*) (0.8.1)\n","Requirement already satisfied, skipping upgrade: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.*) (0.9.0)\n","Requirement already satisfied, skipping upgrade: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.*) (1.18.3)\n","Collecting tensorboard<1.16.0,>=1.15.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1e/e9/d3d747a97f7188f48aa5eda486907f3b345cd409f0a0850468ba867db246/tensorboard-1.15.0-py3-none-any.whl (3.8MB)\n","\u001b[K     |████████████████████████████████| 3.8MB 38.2MB/s \n","\u001b[?25hRequirement already satisfied, skipping upgrade: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.*) (1.12.1)\n","Collecting gast==0.2.2\n","  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n","Requirement already satisfied, skipping upgrade: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.*) (1.1.0)\n","Collecting tensorflow-estimator==1.15.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/62/2ee9cd74c9fa2fa450877847ba560b260f5d0fb70ee0595203082dafcc9d/tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503kB)\n","\u001b[K     |████████████████████████████████| 512kB 33.8MB/s \n","\u001b[?25hRequirement already satisfied, skipping upgrade: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.*) (1.0.8)\n","Requirement already satisfied, skipping upgrade: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.*) (0.2.0)\n","Requirement already satisfied, skipping upgrade: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.*) (3.10.0)\n","Requirement already satisfied, skipping upgrade: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.*) (1.12.0)\n","Requirement already satisfied, skipping upgrade: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.*) (3.2.1)\n","Requirement already satisfied, skipping upgrade: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.*) (46.1.3)\n","Requirement already satisfied, skipping upgrade: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.*) (1.0.1)\n","Requirement already satisfied, skipping upgrade: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow==1.*) (2.10.0)\n","Building wheels for collected packages: gast\n","  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for gast: filename=gast-0.2.2-cp36-none-any.whl size=7540 sha256=78b0d1487416648fa4a0180cfb6acf4e906f8e1b91cf59cdaa298e8e26441d56\n","  Stored in directory: /root/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n","Successfully built gast\n","\u001b[31mERROR: tensorflow-probability 0.10.0rc0 has requirement gast>=0.3.2, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n","Installing collected packages: tensorboard, gast, tensorflow-estimator, tensorflow\n","  Found existing installation: tensorboard 2.2.1\n","    Uninstalling tensorboard-2.2.1:\n","      Successfully uninstalled tensorboard-2.2.1\n","  Found existing installation: gast 0.3.3\n","    Uninstalling gast-0.3.3:\n","      Successfully uninstalled gast-0.3.3\n","  Found existing installation: tensorflow-estimator 2.2.0\n","    Uninstalling tensorflow-estimator-2.2.0:\n","      Successfully uninstalled tensorflow-estimator-2.2.0\n","  Found existing installation: tensorflow 2.2.0rc4\n","    Uninstalling tensorflow-2.2.0rc4:\n","      Successfully uninstalled tensorflow-2.2.0rc4\n","Successfully installed gast-0.2.2 tensorboard-1.15.0 tensorflow-1.15.2 tensorflow-estimator-1.15.1\n","Selecting previously unselected package python-bs4.\n","(Reading database ... 144429 files and directories currently installed.)\n","Preparing to unpack .../0-python-bs4_4.6.0-1_all.deb ...\n","Unpacking python-bs4 (4.6.0-1) ...\n","Selecting previously unselected package python-pkg-resources.\n","Preparing to unpack .../1-python-pkg-resources_39.0.1-2_all.deb ...\n","Unpacking python-pkg-resources (39.0.1-2) ...\n","Selecting previously unselected package python-chardet.\n","Preparing to unpack .../2-python-chardet_3.0.4-1_all.deb ...\n","Unpacking python-chardet (3.0.4-1) ...\n","Selecting previously unselected package python-six.\n","Preparing to unpack .../3-python-six_1.11.0-2_all.deb ...\n","Unpacking python-six (1.11.0-2) ...\n","Selecting previously unselected package python-webencodings.\n","Preparing to unpack .../4-python-webencodings_0.5-2_all.deb ...\n","Unpacking python-webencodings (0.5-2) ...\n","Selecting previously unselected package python-html5lib.\n","Preparing to unpack .../5-python-html5lib_0.999999999-1_all.deb ...\n","Unpacking python-html5lib (0.999999999-1) ...\n","Selecting previously unselected package python-lxml:amd64.\n","Preparing to unpack .../6-python-lxml_4.2.1-1ubuntu0.1_amd64.deb ...\n","Unpacking python-lxml:amd64 (4.2.1-1ubuntu0.1) ...\n","Selecting previously unselected package python-olefile.\n","Preparing to unpack .../7-python-olefile_0.45.1-1_all.deb ...\n","Unpacking python-olefile (0.45.1-1) ...\n","Selecting previously unselected package python-pil:amd64.\n","Preparing to unpack .../8-python-pil_5.1.0-1ubuntu0.2_amd64.deb ...\n","Unpacking python-pil:amd64 (5.1.0-1ubuntu0.2) ...\n","Setting up python-pkg-resources (39.0.1-2) ...\n","Setting up python-six (1.11.0-2) ...\n","Setting up python-bs4 (4.6.0-1) ...\n","Setting up python-lxml:amd64 (4.2.1-1ubuntu0.1) ...\n","Setting up python-olefile (0.45.1-1) ...\n","Setting up python-pil:amd64 (5.1.0-1ubuntu0.2) ...\n","Setting up python-webencodings (0.5-2) ...\n","Setting up python-chardet (3.0.4-1) ...\n","Setting up python-html5lib (0.999999999-1) ...\n","Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"jjXOaDtLQUsc","colab_type":"code","colab":{}},"source":["from __future__ import division, print_function, absolute_import\n","\n","import pandas as pd\n","import numpy as np\n","import csv\n","import re\n","import cv2 \n","import os\n","import glob\n","import xml.etree.ElementTree as ET\n","\n","import io\n","import tensorflow.compat.v1 as tf\n","\n","from PIL import Image\n","from collections import namedtuple, OrderedDict\n","\n","import shutil\n","import urllib.request\n","import tarfile\n","\n","from google.colab import files"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"yuDkZzdrQZ4j","colab_type":"code","outputId":"b471e33e-1c0e-4646-ad8d-c8a4d6fbe232","executionInfo":{"status":"ok","timestamp":1588932989002,"user_tz":-120,"elapsed":1628,"user":{"displayName":"Agnieszka Lipska","photoUrl":"","userId":"15182219769942156159"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["print(tf.__version__)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["1.15.2\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"HPyR-x0SSGAr","colab_type":"code","outputId":"19dea401-8cbb-4bab-f9af-1026976a6976","executionInfo":{"status":"ok","timestamp":1588933006356,"user_tz":-120,"elapsed":10815,"user":{"displayName":"Agnieszka Lipska","photoUrl":"","userId":"15182219769942156159"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["cd '/content/drive/My Drive/malaria-API'"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/malaria-API\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"O2k2I-KESKju","colab_type":"code","outputId":"a9c9e7b2-f062-4d09-ee2f-aaf382c30e99","executionInfo":{"status":"ok","timestamp":1588933011292,"user_tz":-120,"elapsed":14443,"user":{"displayName":"Agnieszka Lipska","photoUrl":"","userId":"15182219769942156159"}},"colab":{"base_uri":"https://localhost:8080/","height":104}},"source":["ls"],"execution_count":0,"outputs":[{"output_type":"stream","text":["'data_reformatted (1).csv'   TensorDetectionAPI.ipynb\n"," data_reformatted.csv        test.json\n"," \u001b[0m\u001b[01;34mimages\u001b[0m/                     training.json\n"," label_map.pbtxt             \u001b[01;34mVOCdevkit\u001b[0m/\n"," \u001b[01;34mmodels\u001b[0m/                     VOCtrainval_11-May-2012.tar\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Oa3FCRX4_dmt","colab_type":"code","colab":{}},"source":["# Creating the `label_map.pbtxt` file\n","label_map_path = os.path.join(\"label_map.pbtxt\")\n","\n","pbtxt_content = \"\"\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"bDoMu6Cs_voq","colab_type":"code","colab":{}},"source":["  classes = ['red blood cell', 'trophozoite', 'schizont', 'difficult', 'ring','leukocyte', 'gametocyte']\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"sUhMUMc6_ick","colab_type":"code","colab":{}},"source":["#creats a pbtxt file the has the class names.\n","for i, class_name in enumerate(classes):\n","    # display_name is optional.\n","    pbtxt_content = (\n","        pbtxt_content\n","        + \"item {{\\n    id: {0}\\n    name: '{1}'\\n    display_name: 'Gun'\\n }}\\n\\n\".format(i + 1, class_name)\n","    )\n","pbtxt_content = pbtxt_content.strip()\n","with open(label_map_path, \"w\") as f:\n","    f.write(pbtxt_content)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"fb9D_RVLArXB","colab_type":"code","outputId":"180b5a6e-1603-4530-a84f-f9056101f4e4","executionInfo":{"status":"ok","timestamp":1588534169511,"user_tz":-120,"elapsed":28075,"user":{"displayName":"Agnieszka Lipska","photoUrl":"","userId":"15182219769942156159"}},"colab":{"base_uri":"https://localhost:8080/","height":729}},"source":["!cat label_map.pbtxt"],"execution_count":0,"outputs":[{"output_type":"stream","text":["item {\n","    id: 1\n","    name: 'red blood cell'\n","    display_name: 'Gun'\n"," }\n","\n","item {\n","    id: 2\n","    name: 'trophozoite'\n","    display_name: 'Gun'\n"," }\n","\n","item {\n","    id: 3\n","    name: 'schizont'\n","    display_name: 'Gun'\n"," }\n","\n","item {\n","    id: 4\n","    name: 'difficult'\n","    display_name: 'Gun'\n"," }\n","\n","item {\n","    id: 5\n","    name: 'ring'\n","    display_name: 'Gun'\n"," }\n","\n","item {\n","    id: 6\n","    name: 'leukocyte'\n","    display_name: 'Gun'\n"," }\n","\n","item {\n","    id: 7\n","    name: 'gametocyte'\n","    display_name: 'Gun'\n"," }"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ftj3L17ACFfv","colab_type":"code","outputId":"b13eccfa-6eeb-4d81-8454-d3c4f62d3761","executionInfo":{"status":"ok","timestamp":1588535782527,"user_tz":-120,"elapsed":7212,"user":{"displayName":"Agnieszka Lipska","photoUrl":"","userId":"15182219769942156159"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["!git clone --q https://github.com/tensorflow/models.git"],"execution_count":0,"outputs":[{"output_type":"stream","text":["fatal: destination path 'models' already exists and is not an empty directory.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"cyxwcsFoCn5T","colab_type":"code","outputId":"317e24ab-3a60-4fc6-d347-333f90f1f1b1","executionInfo":{"status":"ok","timestamp":1588797145384,"user_tz":-120,"elapsed":2044,"user":{"displayName":"Agnieszka Lipska","photoUrl":"","userId":"15182219769942156159"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["cd models/research/"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/malaria-API/models/research\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"uQs8vJqQCynn","colab_type":"code","colab":{}},"source":["!protoc object_detection/protos/*.proto --python_out=."],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"5TF-eifADLkc","colab_type":"code","colab":{}},"source":["os.environ['PYTHONPATH'] += ':/content/drive/My Drive/malaria-API/models/research/:/content/dirve/My Drive/malaria-API/models/research/slim/'"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"3c-Kos6_DjDo","colab_type":"code","outputId":"1b8bec92-157a-41af-d01a-d3765288e216","executionInfo":{"status":"ok","timestamp":1588535447483,"user_tz":-120,"elapsed":1644,"user":{"displayName":"Agnieszka Lipska","photoUrl":"","userId":"15182219769942156159"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["pwd"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'/content/drive/My Drive/malaria-API/models/research'"]},"metadata":{"tags":[]},"execution_count":45}]},{"cell_type":"markdown","metadata":{"id":"pLsHkLmsmFGd","colab_type":"text"},"source":["Downloading and Preparing Tensorflow model\n","\n","    Cloning Tensorflow models from the offical git repo. The repo contains the object detection API we are interseted in.\n","    Compiling the protos and adding folders to the os environment.\n","    Testing the model builder"]},{"cell_type":"code","metadata":{"id":"c6iwqFR6mHw0","colab_type":"code","outputId":"2e04f144-ca8c-439e-b5f6-285941e960f3","executionInfo":{"status":"ok","timestamp":1588611134124,"user_tz":-120,"elapsed":987,"user":{"displayName":"Agnieszka Lipska","photoUrl":"","userId":"15182219769942156159"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["cd '/content/drive/My Drive/malaria-API'"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/malaria-API\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Acjw9hFpm9RP","colab_type":"code","colab":{}},"source":["# Some models to train on\n","MODELS_CONFIG = {\n","    'ssd_mobilenet_v2': {\n","        'model_name': 'ssd_mobilenet_v2_coco_2018_03_29',\n","        'pipeline_file': 'ssd_mobilenet_v2_coco.config',\n","    },\n","    'faster_rcnn_inception_v2': {\n","        'model_name': 'faster_rcnn_inception_v2_coco_2018_01_28',\n","        'pipeline_file': 'faster_rcnn_inception_v2_pets.config',\n","    },\n","    'rfcn_resnet101': {\n","        'model_name': 'rfcn_resnet101_coco_2018_01_28',\n","        'pipeline_file': 'rfcn_resnet101_pets.config',\n","    }\n","}\n","\n","# Select a model in `MODELS_CONFIG`.\n","# I chose ssd_mobilenet_v2 for this project, you could choose any\n","selected_model = 'ssd_mobilenet_v2'"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"-0rsEOjRnMFr","colab_type":"code","outputId":"67d7add7-d2f2-4609-cb21-4fb5d31dd25f","executionInfo":{"status":"ok","timestamp":1588611304726,"user_tz":-120,"elapsed":1229,"user":{"displayName":"Agnieszka Lipska","photoUrl":"","userId":"15182219769942156159"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["pwd"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'/content/drive/My Drive/malaria-API'"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"id":"y0-CuYuym-kG","colab_type":"code","outputId":"f2e1140d-ce7f-4f23-fc18-6dfb0cf05322","executionInfo":{"status":"ok","timestamp":1588933226088,"user_tz":-120,"elapsed":1634,"user":{"displayName":"Agnieszka Lipska","photoUrl":"","userId":"15182219769942156159"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["cd '/content/drive/My Drive/malaria-API/models/research'"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/malaria-API/models/research\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Ao8zGcL-nKBH","colab_type":"code","colab":{}},"source":["# Name of the object detection model to use.\n","MODEL = MODELS_CONFIG[selected_model]['model_name']\n","\n","# Name of the pipline file in tensorflow object detection API.\n","pipeline_file = MODELS_CONFIG[selected_model]['pipeline_file']\n","\n","#selecting the model\n","MODEL_FILE = MODEL + '.tar.gz'\n","\n","#creating the downlaod link for the model selected\n","DOWNLOAD_BASE = 'http://download.tensorflow.org/models/object_detection/'\n","\n","#the distination folder where the model will be saved\n","fine_tune_dir = '/content/drive/My Drive/malaria-API/models/research/pretrained_model'\n","\n","#checks if the model has already been downloaded\n","if not (os.path.exists(MODEL_FILE)):\n","    urllib.request.urlretrieve(DOWNLOAD_BASE + MODEL_FILE, MODEL_FILE)\n","\n","#unzipping the file and extracting its content\n","tar = tarfile.open(MODEL_FILE)\n","tar.extractall()\n","tar.close()\n","\n","# creating an output file to save the model while training\n","os.remove(MODEL_FILE)\n","if (os.path.exists(fine_tune_dir)):\n","    shutil.rmtree(fine_tune_dir)\n","os.rename(MODEL, fine_tune_dir)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"CtbotQbqnxjZ","colab_type":"code","outputId":"5be30a00-6283-48d2-af7c-8b61dba41015","executionInfo":{"status":"ok","timestamp":1588611545463,"user_tz":-120,"elapsed":7159,"user":{"displayName":"Agnieszka Lipska","photoUrl":"","userId":"15182219769942156159"}},"colab":{"base_uri":"https://localhost:8080/","height":69}},"source":["#checking the content of the pretrained model.\n","# this is the directory of the \"fine_tune_checkpoint\" that is used in the config file.\n","!echo {fine_tune_dir}\n","!ls -alh {fine_tune_dir}"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/malaria-API/models/research/pretrained_model\n","ls: cannot access '/content/drive/My': No such file or directory\n","ls: cannot access 'Drive/malaria-API/models/research/pretrained_model': No such file or directory\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"j1DA6xoUoVPa","colab_type":"code","outputId":"4565c702-346a-41c4-c36f-b96aa2caa92a","executionInfo":{"status":"ok","timestamp":1588933256505,"user_tz":-120,"elapsed":1410,"user":{"displayName":"Agnieszka Lipska","photoUrl":"","userId":"15182219769942156159"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["#the path to the folder containing all the sample config files\n","CONFIG_BASE = \"/content/drive/My Drive/malaria-API/models/research/object_detection/samples/configs/\"\n","\n","#path to the specified model's config file\n","model_pipline = os.path.join(CONFIG_BASE, pipeline_file)\n","model_pipline"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'/content/drive/My Drive/malaria-API/models/research/object_detection/samples/configs/ssd_mobilenet_v2_coco.config'"]},"metadata":{"tags":[]},"execution_count":16}]},{"cell_type":"code","metadata":{"id":"z5nsAKEwojqf","colab_type":"code","colab":{}},"source":["%%writefile {model_pipline}\n","model {\n","  ssd {\n","    num_classes: 7 # number of classes to be detected\n","    box_coder {\n","      faster_rcnn_box_coder {\n","        y_scale: 10.0\n","        x_scale: 10.0\n","        height_scale: 5.0\n","        width_scale: 5.0\n","      }\n","    }\n","    matcher {\n","      argmax_matcher {\n","        matched_threshold: 0.5\n","        unmatched_threshold: 0.5\n","        ignore_thresholds: false\n","        negatives_lower_than_unmatched: true\n","        force_match_for_each_row: true\n","      }\n","    }\n","    similarity_calculator {\n","      iou_similarity {\n","      }\n","    }\n","    anchor_generator {\n","      ssd_anchor_generator {\n","        num_layers: 6\n","        min_scale: 0.2\n","        max_scale: 0.95\n","        aspect_ratios: 1.0\n","        aspect_ratios: 2.0\n","        aspect_ratios: 0.5\n","        aspect_ratios: 3.0\n","        aspect_ratios: 0.3333\n","      }\n","    }\n","    # all images will be resized to the below W x H.\n","    image_resizer { \n","      fixed_shape_resizer {\n","        height: 300\n","        width: 300\n","      }\n","    }\n","    box_predictor {\n","      convolutional_box_predictor {\n","        min_depth: 0\n","        max_depth: 0\n","        num_layers_before_predictor: 0\n","        #use_dropout: false\n","        use_dropout: true # to counter over fitting. you can also try tweaking its probability below\n","        dropout_keep_probability: 0.8\n","        kernel_size: 1\n","        box_code_size: 4\n","        apply_sigmoid_to_scores: false\n","        conv_hyperparams {\n","          activation: RELU_6,\n","          regularizer {\n","            l2_regularizer {\n","            # weight: 0.00004\n","            weight: 0.001 # higher regularizition to counter overfitting\n","          }\n","          }\n","          initializer {\n","            truncated_normal_initializer {\n","              stddev: 0.03\n","              mean: 0.0\n","            }\n","          }\n","          batch_norm {\n","            train: true,\n","            scale: true,\n","            center: true,\n","            decay: 0.9997,\n","            epsilon: 0.001,\n","          }\n","        }\n","      }\n","    }\n","    feature_extractor {\n","      type: 'ssd_mobilenet_v2'\n","      min_depth: 16\n","      depth_multiplier: 1.0\n","      conv_hyperparams {\n","        activation: RELU_6,\n","        regularizer {\n","          l2_regularizer {\n","            # weight: 0.00004\n","            weight: 0.001 # higher regularizition to counter overfitting\n","          }\n","        }\n","        initializer {\n","          truncated_normal_initializer {\n","            stddev: 0.03\n","            mean: 0.0\n","          }\n","        }\n","        batch_norm {\n","          train: true,\n","          scale: true,\n","          center: true,\n","          decay: 0.9997,\n","          epsilon: 0.001,\n","        }\n","      }\n","    }\n","    loss {\n","      classification_loss {\n","        weighted_sigmoid {\n","        }\n","      }\n","      localization_loss {\n","        weighted_smooth_l1 {\n","        }\n","      }\n","      hard_example_miner {\n","        num_hard_examples: 3000 \n","        iou_threshold: 0.95\n","        loss_type: CLASSIFICATION\n","        max_negatives_per_positive: 3\n","        min_negatives_per_image: 3\n","      }\n","      classification_weight: 1.0\n","      localization_weight: 1.0\n","    }\n","    normalize_loss_by_num_matches: true\n","    post_processing {\n","      batch_non_max_suppression {\n","        score_threshold: 1e-8\n","        iou_threshold: 0.6\n","        \n","        #adjust this to the max number of objects per class. \n","        # ex, in my case, i have one pistol in most of the images.\n","        # . there are some images with more than one up to 16.\n","        max_detections_per_class: 219\n","        # max number of detections among all classes. I have 1 class only so\n","        max_total_detections: 634\n","      }\n","      score_converter: SIGMOID\n","    }\n","  }\n","}\n","\n","train_config: {\n","  batch_size: 16 # training batch size\n","  optimizer {\n","    rms_prop_optimizer: {\n","      learning_rate: {\n","        exponential_decay_learning_rate {\n","          initial_learning_rate: 0.003\n","          decay_steps: 800720\n","          decay_factor: 0.95\n","        }\n","      }\n","      momentum_optimizer_value: 0.9\n","      decay: 0.9\n","      epsilon: 1.0\n","    }\n","  }\n","\n","  #the path to the pretrained model. \n","  fine_tune_checkpoint: \" /content/drive/My Drive/malaria-API/models/research/pretrained_model/model.ckpt\"\n","  fine_tune_checkpoint_type:  \"detection\"\n","  # Note: The below line limits the training process to 200K steps, which we\n","  # empirically found to be sufficient enough to train the pets dataset. This\n","  # effectively bypasses the learning rate schedule (the learning rate will\n","  # never decay). Remove the below line to train indefinitely.\n","  num_steps: 200000 \n","  \n","\n","  #data augmentaion is done here, you can remove or add more.\n","  # They will help the model generalize but the training time will increase greatly by using more data augmentation.\n","  # Check this link to add more image augmentation: https://github.com/tensorflow/models/blob/master/research/object_detection/protos/preprocessor.proto\n","  \n","  data_augmentation_options {\n","    random_horizontal_flip {\n","    }\n","  }\n","  data_augmentation_options {\n","    random_adjust_contrast {\n","    }\n","  }\n","  data_augmentation_options {\n","    ssd_random_crop {\n","    }\n","  }\n","}\n","\n","train_input_reader: {\n","  tf_record_input_reader {\n","    #path to the training TFRecord\n","    input_path: \"/content/gun_detection/data/train_labels.record\"\n","  }\n","  #path to the label map \n","  label_map_path: \"/content/gun_detection/data/label_map.pbtxt\"\n","}\n","\n","eval_config: {\n","  # the number of images in your \"testing\" data (was 600 but we removed one above :) )\n","  num_examples: 599\n","  # the number of images to disply in Tensorboard while training\n","  num_visualizations: 20\n","\n","  # Note: The below line limits the evaluation process to 10 evaluations.\n","  # Remove the below line to evaluate indefinitely.\n","  #max_evals: 10\n","}\n","\n","eval_input_reader: {\n","  tf_record_input_reader {\n","      \n","    #path to the testing TFRecord\n","    input_path: \"/content/gun_detection/data/test_labels.record\"\n","  }\n","  #path to the label map \n","  label_map_path: \"/content/gun_detection/data/label_map.pbtxt\"\n","  shuffle: false\n","  num_readers: 1"],"execution_count":0,"outputs":[]}]}